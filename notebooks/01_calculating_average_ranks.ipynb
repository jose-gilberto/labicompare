{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from labicompare.stats import calculate_average_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR</th>\n",
       "      <th>LDA</th>\n",
       "      <th>KNN</th>\n",
       "      <th>DT</th>\n",
       "      <th>NB</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.020271</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.955112</td>\n",
       "      <td>0.945968</td>\n",
       "      <td>0.974231</td>\n",
       "      <td>0.829593</td>\n",
       "      <td>0.837074</td>\n",
       "      <td>0.976725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016869</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.921260</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.916010</td>\n",
       "      <td>0.913386</td>\n",
       "      <td>0.955381</td>\n",
       "      <td>0.908136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.969994</td>\n",
       "      <td>0.970291</td>\n",
       "      <td>0.960190</td>\n",
       "      <td>0.939691</td>\n",
       "      <td>0.980095</td>\n",
       "      <td>0.949792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         LR       LDA       KNN        DT        NB       SVM\n",
       "0  0.020271  0.003401  0.000000  0.000000  0.000000  0.013468\n",
       "1  0.955112  0.945968  0.974231  0.829593  0.837074  0.976725\n",
       "2  0.016869  0.003367  0.000000  0.010101  0.000000  0.020236\n",
       "3  0.921260  0.944882  0.916010  0.913386  0.955381  0.908136\n",
       "4  0.969994  0.970291  0.960190  0.939691  0.980095  0.949792"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = pd.read_csv('example_metrics.csv')\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LR     2.4\n",
       "LDA    3.0\n",
       "KNN    4.1\n",
       "DT     5.0\n",
       "NB     3.5\n",
       "SVM    3.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To calculate the average ranks we only need to call the \n",
    "# `calculate_average_ranks` method and pass the metrics\n",
    "\n",
    "# REMEMBER: the csv file must have the models as its columns\n",
    "# and for each row the dataset metrics in each model\n",
    "\n",
    "# For now you can save a file for accuracies, f1 and any other\n",
    "# metrics that you want to compare, but must be in separeted files!\n",
    "calculate_average_ranks(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
